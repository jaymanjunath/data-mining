{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TwitterMining\n",
    "\n",
    "Goal: Predict the animal classification of tweets (cat or dog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boilerplate code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import modules\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.feature_extraction import text as sk_fe_text\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, f1_score, recall_score\n",
    "from TwitterAPI import TwitterAPI\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Twitter api key\n",
    "api = TwitterAPI('QNfuwJhdHesrXfpVmYGYx9UYi', '8ZTHg0osCzwOqxvmqwZUNI1KaWu2PI9C4tao29VeEp0UlzlTbH', auth_type = 'oAuth2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(true,pred):\n",
    "    return (precision_score(true,pred),\n",
    "            recall_score(true,pred),\n",
    "            f1_score(true,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_score(s):\n",
    "    print (\"\"\"\n",
    "Precision: {:0.3}\n",
    "Recall:    {:0.3}\n",
    "F-SCore:   {:0.3}\n",
    "\"\"\".format(*s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def searchTwitter(query,feed=\"search/tweets\",api=api,n=10000):\n",
    "  r = []\n",
    "  qs = 0\n",
    "  if len(r)==0:\n",
    "    r.extend([t for t in api.request(\"search/tweets\",{'q':query,'count':n})])\n",
    "    qs +=1\n",
    "  while len(r) < n:\n",
    "#     print(\"Querrying twitter for {}. {}/{} gathered.\".format(query,len(r),n))\n",
    "    last = r[-1]['id']\n",
    "    r.extend([t for t in api.request(\"search/tweets\",{'q':query,'count':n,\n",
    "                                                        'max_id':last})])\n",
    "    qs += 1\n",
    "    if qs > 180:\n",
    "      time.sleep(840)\n",
    "      qs = 0\n",
    "  return r[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tweets from Twitter\n",
    "cats = searchTwitter('#cats')\n",
    "dogs = searchTwitter('#dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#converting json from Twitter into a dataframe\n",
    "cats_d_sub = pd.read_json(json.dumps(cats[:2000]))\n",
    "dogs_d_sub = pd.read_json(json.dumps(dogs[:2000]))\n",
    "cats_d = pd.read_json(json.dumps(cats))\n",
    "dogs_d = pd.read_json(json.dumps(dogs))\n",
    "\n",
    "#display(cats_d)\n",
    "#display(dogs_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2,000 Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get text only and replace hashtags with blanks\n",
    "cats_text = [x.replace(\"#cats\", \"\") for x in cats_d_sub['text']]\n",
    "dogs_text = [x.replace(\"#dogs\", \"\") for x in dogs_d_sub['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find the number of times #dogs appear in the cats data\n",
    "blob = [x.find(\"#dogs\") for x in cats_text]\n",
    "type(blob)\n",
    "df1 = pd.DataFrame(blob)\n",
    "#df1.stack().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create features and return sparse metrics \n",
    "vectorizer = sk_fe_text.CountVectorizer(cats_text+dogs_text)\n",
    "vectorizer.fit(cats_text+dogs_text)\n",
    "cats_tdm = vectorizer.transform(cats_text).toarray()\n",
    "dogs_tdm = vectorizer.transform(dogs_text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create visible matrices, combine and add the number of times #dogs appear in cats_text to the length of dog_text and subtract\n",
    "#the same number from the length of cats_text\n",
    "zeros = np.zeros((len(cats_text) - 185, 1))\n",
    "ones = np.ones((len(dogs_text) + 185, 1))\n",
    "catsdogs = np.concatenate((cats_tdm,dogs_tdm),axis=0)\n",
    "y = np.ravel(np.concatenate((zeros,ones),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create train/test split for modeling\n",
    "trainX_sub,testX_sub,trainY_sub,testY_sub = train_test_split(catsdogs,y,test_size=.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(trainX_sub,trainY_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Naive Bayes Performance (2,000)\n",
      "\n",
      "Precision: 0.911\n",
      "Recall:    0.806\n",
      "F-SCore:   0.855\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes cont'd\n",
    "print(\"\\n\\nNaive Bayes Performance (2,000)\")\n",
    "s = score(testY_sub,nb.predict(testX_sub))\n",
    "print_score(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10,000 Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get text only and replace hashtags with blanks\n",
    "cats_text = [x.replace(\"#cats\", \"\") for x in cats_d['text']]\n",
    "dogs_text = [x.replace(\"#dogs\", \"\") for x in dogs_d['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find the number of times #dogs appear in the cats data\n",
    "blob = [x.find(\"#dogs\") for x in cats_text]\n",
    "type(blob)\n",
    "df1 = pd.DataFrame(blob)\n",
    "#df1.stack().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create features and return sparse metrics \n",
    "vectorizer = sk_fe_text.CountVectorizer(cats_text+dogs_text)\n",
    "vectorizer.fit(cats_text+dogs_text)\n",
    "cats_tdm = vectorizer.transform(cats_text).toarray()\n",
    "dogs_tdm = vectorizer.transform(dogs_text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create visible matrices, combine and add the number of times #dogs appear in cats_text to the length of dog_text and subtract\n",
    "#the same number from the length of cats_text\n",
    "zeros = np.zeros((len(cats_text) - 185, 1))\n",
    "ones = np.ones((len(dogs_text) + 185, 1))\n",
    "catsdogs = np.concatenate((cats_tdm,dogs_tdm),axis=0)\n",
    "y = np.ravel(np.concatenate((zeros,ones),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create train/test split for modeling\n",
    "trainX,testX,trainY,testY = train_test_split(catsdogs,y,test_size=.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Naive Bayes Performance (10,000)\n",
      "\n",
      "Precision: 0.94\n",
      "Recall:    0.775\n",
      "F-SCore:   0.85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes cont'd\n",
    "print(\"\\n\\nNaive Bayes Performance (10,000)\")\n",
    "s = score(testY,nb.predict(testX))\n",
    "print_score(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2,000 Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Neural Network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "nn = MLPClassifier()\n",
    "nn.fit(trainX_sub,trainY_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Neural Network Performance (2,000)\n",
      "\n",
      "Precision: 0.894\n",
      "Recall:    0.856\n",
      "F-SCore:   0.875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Neural Network cont'd\n",
    "print(\"\\n\\nNeural Network Performance (2,000)\")\n",
    "s = score(testY_sub,nn.predict(testX_sub))\n",
    "print_score(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 10,000 Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Neural Network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "nn = MLPClassifier()\n",
    "nn.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Neural Network Performance (10,000)\n",
      "\n",
      "Precision: 0.929\n",
      "Recall:    0.905\n",
      "F-SCore:   0.917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### Neural Network cont'd\n",
    "print(\"\\n\\nNeural Network Performance (10,000)\")\n",
    "s = score(testY,nn.predict(testX))\n",
    "print_score(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
